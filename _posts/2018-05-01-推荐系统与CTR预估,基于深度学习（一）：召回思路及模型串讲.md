---
layout:     post
title: 推荐系统与CTR预估， 基于深度学习（一):召回思路及模型串讲
date:       2018-05-01 12:01:00
author:     "nickiwei"
header-img: "img/post-bg-2015.jpg"
tags:
    - 深度学习
    - DSSM
---

这个系列介绍了在深度学习的大背景下， 推荐系统领域所发生的翻天覆地的变化。 从召回和排序模型串讲开始， 结合论文总结与工程实践， 并充分记录了作者在实际工作中所总结的各种经验总结。

欢迎转载， 转载请注明出处及链接。

# 基于深度学习的推荐系统基本架构
 一个推荐系统的架构其实并不复杂， 基本上就是召回， 排序， 规则三个部分。

![Architecture](/img/RC01.jpg)

召回模型负责根据用户和场景特征， 从众多的内容通道中抓取用户可能感兴趣的内容， 召回模型可能是多通道并行的， 通道与通道之间互不影响。召回模型也叫做触发模型。

排序模型根据CTR等指标， 对来自不同通道的所有召回内容进行排序。 在Feeds中， 内容按照排序模型的输出自上而下显示， 在广告推荐中， 选择CTR最高的若干个进行展示。除了合并通道的原因以外， 召回和排序两个阶段所使用的特征也大不相同， 这样的做法可以避免单模型特征爆炸。

规则部分则是对模型的补充。在实践中主要起到两个方面的作用， 

* 处理系统对于多样性， 实效性等的个性化需求。
* 应对一些特殊的， 紧急的需求， 做hard code.

这个系列中， 我们将依序介绍这三个部分， 本文重点介绍召回模型。我们将着重记述两大类召回模型， 分别是微软自2013年起发表的DSSM模型系列， 以及Youtube在2017发布的Youtube DNN模型。

# DSSM

DSSM是微软2013年发表的一个query/doc相似度计算模型， 后来被发展成一种框架广泛的应用在各种召回， 排序问题中。

## Original DSSM

我们首先来看一下基本的DSSM模型：

![DSSM](/img/ZH01.png)

模型很容易理解， 首先， 我们将Query和Doc词向量（one hot）转化为embedding向量， 这里， 针对英文输入， 原论文中提出了一种特殊的embedding方法， 用来显著降低embedding字典规模， 称为word hashing， 但是中文中这种方式不是很适用， 我们在中文embedding时， 使用传统的方式进行embedding即可（word hashing 方法会在下一部分详细介绍）


经过embedding后的词向量， 会喂给DNN进行多层projection， 与绝大多数nlp问题一致， 我们选择tanh激活函数。 之后， Query和Doc向量会进行一次cos相似度计算， 得到R(Q, Dn), 各个R(Q, Dn)通过softmax归一化后得到最终的指标P(Dn|Q).

公式如下：

![DSSM](/img/ZH03.jpg)

![DSSM](/img/ZH04.png)

在实际的训练中， 我们提出一种类似word2vec negative sampling的负采样方式进行训练。在每一次迭代中， 我们都选取一个正样本和四个负样本， 最后的loss计算中， 我们取负采样交叉商， P(D+|Q)取正loss， P(D-|Q)取负loss， 如下图:

![DSSM](/img/ZH07.jpg)

## DSSM 的衍化

DSSM的key idea是：

### 将不同的对象映射到同一个语义空间中， 利用该语义空间中的距离计算相似度。

这一思路被广泛的应用到了 召回， 排序， 搜索等各种工程实践中。 在应用过程中， 我们更多是使用一个如下图的DSSM的模子， 然后再框架内部根据实际任务填充不同的拓扑：

![DSSM](/img/ZH05.jpg)

如上图， 我们将不同对象通过embedding 映射到同一语义空间中， 经过随机填充的不同拓扑（如FCN， CNN， RNN， LTR等）， 最终形成一个等维向量， 在定义一个距离公式sim(X, Y), 求得不同对象在该语义空间中的距离。 通常情况下， 我们均使用cos距离即可。 所以模型的核心是根据不同的任务类型， 选择合适的f， g函数拓扑。 所谓的CNN-DSSM, LTR-DSSM都是这种框架的一个应用而已。

常见的DSSM变形应用有：

* 在CTR预估中，对点击与否做0，1二元分类，添加交叉熵损失变成一个分类模型

数据格式：
	
	- source word list   - target word list   - target
	苹果 六 袋    苹果 6s    0
	新手 汽车 驾驶    驾校 培训    1

* 在需要对一个子串打分时，可以使用余弦相似度来计算相似度，变成一个回归模型

数据格式：
	
	- source word list   - target word list   - target
	苹果 六 袋    苹果 6s    0.1
	新手 汽车 驾驶    驾校 培训    0.9

* 在排序学习中，在可变结构中添加 pairwise rank损失，变成一个排序模型（具体查看我的另一篇文章： 推荐系统与CTR预估（三）: LTR排序模型）

数据格式：

	   - source word list   - target1 word list   - target2 word list   - label
	   苹果 六 袋    苹果 6s    新手 汽车 驾驶    1
	   新手 汽车 驾驶    驾校 培训    苹果 6s    1


值得注意的是， 在排序模型中， 我们需要用到多个DSSM可变模型的组合。如下图：

![DSSM](/img/ZH06.jpg)

# 更多召回模型

## MVDSSM 和 TDDSSM

除了改动DSSM的可变结构外， 我们还提出了两种对DSSM模型的优化。这两个模型我们将在下一篇中详细介绍。

## Youtube DNN

除了DSSM外， Youtube在2017年提出了一套独立的模型拓扑设计， 取得了非常不错的效果。 我们将在下一章中对比DSSM和Youtube DNN的区别。

## 更多召回

除了给予用户行为的推荐召回外， 一般的， 我们还会引入其他的一些规则召回方式。 如热度召回等。 我们同样会在下一章详细介绍。



